<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Manh Tuan Do | AI & Research</title>
  <style>
    /* ========== Variables & Reset ========== */
    :root {
      --primary: #1a237e;       /* deep indigo */
      --accent: #ff6f00;        /* vibrant orange */
      --bg: #f5f5f5;
      --text: #333;
      --light: #fff;
    }
    /* â€”â€” About paragraphs: justify & spacing â€”â€” */
    #about p {
      text-align: justify;    /* cÄƒn Ä‘á»u hai bÃªn */
      line-height: 1.6;       /* tÄƒng khoáº£ng cÃ¡ch giá»¯a cÃ¡c dÃ²ng */
      margin-bottom: 1.5em;   /* cÃ¡ch Ä‘oáº¡n tiáº¿p theo 1.5em */
    }
    
    /* â€”â€” Research Interests Styling - FIXED VERSION â€”â€” */
    #research {
      padding: 5rem 2rem 3rem 2rem; /* TÄƒng padding-top Ä‘á»ƒ cÃ³ chá»— cho icon */
      background: var(--light);
      position: relative; /* Quan trá»ng Ä‘á»ƒ icon cÃ³ thá»ƒ Ä‘á»‹nh vá»‹ tuyá»‡t Ä‘á»‘i */
    }
    
    /* Section title with underline */
    #research h2 {
      font-size: 2rem;
      color: var(--primary);
      margin-bottom: 3rem; /* TÄƒng margin-bottom Ä‘á»ƒ táº¡o khoáº£ng trá»‘ng cho icon */
      position: relative;
      display: inline-block;
    }
    #research h2::after {
      content: "";
      position: absolute;
      left: 0; bottom: -6px;
      width: 60px; height: 4px;
      background: var(--accent);
      border-radius: 2px;
    }
    
    /* Grid container */
    .research-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
      gap: 1.5rem;
      list-style: none;
      margin: 2rem 0 0 0; /* ThÃªm margin-top Ä‘á»ƒ táº¡o khoáº£ng trá»‘ng */
      padding: 0;
      position: relative; /* Cho phÃ©p children absolute positioning */
    }
    
    /* Card base - FIXED */
    .card {
      position: relative;
      background: #fafafa;
      border-radius: 12px;
      border-top: 4px solid var(--accent);
      padding: 3rem 1.5rem 1.5rem; /* TÄƒng padding-top Ä‘á»ƒ cÃ³ chá»— cho icon */
      margin-top: 35px; /* Táº¡o khoáº£ng trá»‘ng phÃ­a trÃªn Ä‘á»ƒ icon khÃ´ng bá»‹ cáº¯t */
      box-shadow: 0 4px 12px rgba(0,0,0,0.05);
      transition: transform 0.3s ease, box-shadow 0.3s ease;
      overflow: visible; /* Cho phÃ©p icon hiá»ƒn thá»‹ bÃªn ngoÃ i */
    }
    
    .card:hover {
      transform: translateY(-8px);
      box-shadow: 0 8px 20px rgba(0,0,0,0.12);
    }
    
    /* Icon circle - FIXED positioning */
    .icon-wrapper {
      position: absolute;
      top: -35px; /* Äáº·t icon trÃªn cÃ¹ng cá»§a card */
      left: 50%;
      transform: translateX(-50%);
      width: 70px; 
      height: 70px;
      background: linear-gradient(135deg, var(--primary), var(--accent));
      border-radius: 50%;
      display: flex; 
      align-items: center; 
      justify-content: center;
      z-index: 2;
      box-shadow: 0 4px 12px rgba(0,0,0,0.15); /* ThÃªm shadow cho icon */
    }
    
    /* Icon placeholder - sá»­ dá»¥ng Unicode symbols thay vÃ¬ img */
    .icon-wrapper::before {
      content: attr(data-icon);
      font-size: 32px;
      color: white;
      font-weight: bold;
    }
    
    /* Text container */
    .card-content {
      text-align: center;
      margin-top: 0.5rem;
    }
    
    .card-content h3 {
      font-size: 1.1rem;
      color: var(--primary);
      margin-bottom: 0.5rem;
      font-weight: 600;
    }
    
    .card-content p {
      font-size: 0.9rem;
      color: #555;
      line-height: 1.4;
    }

    /* ========== Other styles remain the same ========== */
    * { margin:0; padding:0; box-sizing:border-box; }
    body { font-family: 'Segoe UI', sans-serif; background: var(--bg); color: var(--text); line-height:1.5; }
    a { color: var(--accent); text-decoration:none; }
    img { max-width:100%; display:block; }

    /* ========== Navbar ========== */
    nav { position: sticky; top:0; background: var(--primary); padding: .5rem 2rem; z-index:10; }
    nav ul { display:flex; list-style:none; justify-content: center; }
    nav li { margin: 0 .8rem; }
    nav a { color: var(--light); font-weight:600; transition: .3s; }
    nav a:hover { color: var(--accent); }

    /* ========== Hero ========== */
    .hero { display:flex; flex-wrap: wrap; align-items:center; justify-content:center; text-align:center;
            padding:4rem 2rem; background: linear-gradient(120deg, var(--primary), var(--accent)); color:var(--light);}
    .hero img { width:180px; height:180px; border-radius:50%; border:4px solid var(--light); margin-bottom:1rem; }
    .hero h1 { font-size:2.5rem; margin-bottom:.3rem; }
    .hero p { font-size:1.2rem; opacity:.9; }

    /* ========== Section Titles ========== */
    section { padding:3rem 2rem; max-width:1000px; margin:auto; }
    h2 { font-size:2rem; margin-bottom:1rem; color: var(--primary); border-bottom:2px solid var(--accent); display:inline-block; padding-bottom:.2rem; }

    /* ========== About Tabs - Enhanced Design ========== */
    .tabs { 
      display: flex; 
      margin: 2rem 0 0 0; 
      background: #f8f9fa;
      border-radius: 12px;
      padding: 6px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.05);
    }
    
    .tabs button { 
      flex: 1; 
      padding: 1rem 2rem; 
      cursor: pointer; 
      background: transparent; 
      border: none;
      border-radius: 8px;
      font-weight: 600;
      font-size: 1rem;
      color: #666;
      transition: all 0.3s ease;
      position: relative;
      overflow: hidden;
    }
    
    .tabs button::before {
      content: '';
      position: absolute;
      top: 0; left: 0; right: 0; bottom: 0;
      background: linear-gradient(135deg, var(--primary), var(--accent));
      opacity: 0;
      transition: opacity 0.3s ease;
      z-index: -1;
    }
    
    .tabs button:hover {
      color: var(--primary);
      transform: translateY(-2px);
    }
    
    .tabs button.active { 
      background: linear-gradient(135deg, var(--primary), var(--accent));
      color: var(--light); 
      box-shadow: 0 4px 12px rgba(26, 35, 126, 0.3);
      transform: translateY(-2px);
    }
    
    .tabs button.active::before {
      opacity: 1;
    }
    
    .tab-content { 
      background: var(--light); 
      border-radius: 12px;
      margin-top: 1.5rem;
      overflow: hidden;
      box-shadow: 0 4px 20px rgba(0,0,0,0.08);
    }
    
    .tab-content > div { 
      display: none; 
      animation: fadeOut 0.3s ease;
    }
    
    .tab-content > div.active { 
      display: block; 
      animation: fadeIn 0.5s ease;
    }
    
    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(20px); }
      to { opacity: 1; transform: translateY(0); }
    }
    
    @keyframes fadeOut {
      from { opacity: 1; transform: translateY(0); }
      to { opacity: 0; transform: translateY(-20px); }
    }
    
    /* Timeline-style list items */
    .tab-content ul {
      list-style: none;
      padding: 0;
      margin: 0;
    }
    
    .tab-content li {
      padding: 1.5rem 2rem;
      border-left: 4px solid var(--accent);
      margin-bottom: 0;
      position: relative;
      background: linear-gradient(90deg, 
        rgba(255, 111, 0, 0.05) 0%, 
        rgba(255, 111, 0, 0.02) 30%, 
        transparent 100%);
      transition: all 0.3s ease;
    }
    
    .tab-content li:hover {
      background: linear-gradient(90deg, 
        rgba(255, 111, 0, 0.08) 0%, 
        rgba(255, 111, 0, 0.04) 40%, 
        transparent 100%);
      transform: translateX(8px);
      border-left-color: var(--primary);
    }
    
    .tab-content li:not(:last-child) {
      border-bottom: 1px solid #f0f0f0;
    }
    
    .tab-content li::before {
      content: '';
      position: absolute;
      left: -8px;
      top: 50%;
      transform: translateY(-50%);
      width: 12px;
      height: 12px;
      background: var(--accent);
      border-radius: 50%;
      box-shadow: 0 0 0 4px var(--light);
      transition: all 0.3s ease;
    }
    
    .tab-content li:hover::before {
      background: var(--primary);
      transform: translateY(-50%) scale(1.2);
    }
    
    .tab-content li strong {
      color: var(--primary);
      font-weight: 700;
      font-size: 1.1em;
      display: inline-block;
      margin-right: 0.8rem;
      min-width: 100px;
    }
    
    /* Responsive design */
    @media (max-width: 768px) {
      .tabs {
        flex-direction: column;
        padding: 4px;
      }
      
      .tabs button {
        margin-bottom: 4px;
      }
      
      .tab-content li {
        padding: 1rem 1.5rem;
      }
      
      .tab-content li strong {
        display: block;
        margin-bottom: 0.5rem;
        min-width: auto;
      }
    }

    /* ========== Projects Grid ========== */
    .grid { display:grid; grid-template-columns:repeat(auto-fit, minmax(280px, 1fr)); gap:1.5rem; }
    .project-card { background: var(--light); border-radius:8px; overflow:hidden; box-shadow:0 2px 6px rgba(0,0,0,.1); transition:.3s; }
    .project-card:hover { transform: translateY(-5px); box-shadow:0 4px 12px rgba(0,0,0,.15); }
    .project-card img { height:160px; object-fit:cover; }
    .project-card-content { padding:1rem; }
    .project-card-content h3 { margin-bottom:.5rem; color:var(--primary); }
    .project-card-content p { font-size:.95rem; margin-bottom:.8rem; }
    .project-card-content .links a { margin-right:.8rem; font-weight:600; }

    /* ========== Accordion Publications ========== */
    .accordion .item { margin-bottom:.6rem; }
    .accordion button { width:100%; background:var(--accent); color:var(--light); border:none; 
                        padding:.8rem 1rem; text-align:left; font-size:1rem; cursor:pointer; }
    .accordion .content { display:none; padding:1rem; border:1px solid #ccc; border-top:none; background:var(--light); }
    .accordion .item.open .content { display:block; }

    /* ========== Challenge Myself ========== */
    .challenge-list li { background: var(--light); padding:1rem; margin-bottom:.8rem; border-radius:6px;
                         border-left:4px solid var(--accent); }
    .challenge-list li a { margin-right:1rem; font-weight:600; }

    /* ========== Footer ========== */
    footer { background:#222; color:#eee; padding:2rem; text-align:center; }
    footer a { color: #ffab40; }

  </style>
</head>
<body>

  <!-- Nav -->
  <nav>
    <ul>
      <li><a href="#about">About</a></li>
      <li><a href="#research">Research</a></li>
      <li><a href="#projects">Projects</a></li>
      <li><a href="#publications">Publications</a></li>
      <li><a href="#blog">Challenge</a></li>
      <li><a href="#contact">Contact</a></li>
    </ul>
  </nav>

  <!-- Hero -->
  <section class="hero" id="hero">
    <img
      src="avatar.jpg"
      alt="Avatar"
      style="width:180px; height:180px; object-fit:cover; border-radius:50%; border:4px solid white;"
    >
    <div>
      <h1>Manh Tuan Do</h1>
      <p>AI & Computer Vision Enthusiast | M.Sc. Student @Paris-Saclay</p>
    </div>
  </section>

<!-- About --> 
<section id="about">
  <h2>About Me</h2>

  <p>
    My name is Manh Tuan Do. In 2023, I graduated with a Bachelor of Mechatronics (Valedictorian) at Vietnam National University, Hanoi (VNU), then I was retained as a teaching assistant at VNU under the guidance of 
    <a href="https://scholar.google.com/citations?user=MhdodIIAAAAJ&hl=vi">Dr. Ha Manh Hung</a> 
    and conducted research work with 
    <a href="https://ee.ccu.edu.tw/p/412-1097-558.php?Lang=en">Prof. Oscal T.-C. Chen</a>.  
    In 2024, I received a fully-funded scholarship for a Master's M1 in Electrical Engineering (Computer Vision & AI track) at Paris-Saclay University.  
    Now I am studying M2 in Mechatronics, Machine Vision, and Artificial Intelligence also at Paris-Saclay University, and I am fortunate and honored to be a research intern at Westlake under the guidance of 
    <a href="https://huanwang.tech" target="_blank">Prof. Huan Wang</a>.
  </p>

  <p>
    In terms of my research interests, initially, when I was a bachelor student combined with the foundation in robotics and mechatronics, I decided to focus on AI applications including the implementation of AI lightweight models into hardware, embedded systems, microcontrollers to make the system more intelligent in course projects and student research.  
    Up to the thesis, I began modifying the architecture of models by finding ways to optimize the model for lightweight and accuracy improvements in the object detection problem, specifically in the YOLO model.
  </p>

  <p>
    Recently, I have been exploring 3D object detection and 3D reconstruction using geometric methods like SFM and using DNNs like NeRF.  
    Besides, I have studied GAN-based data augmentation and unpaired neural style transfer between images of two classes (cow, horse).  
  </p>

  <p>
    May not yet I have a pure foundation in math or computer science, but I can affirm that I am on the journey to becoming a genuine AI research expert in the near future. Waiting for me !!
  </p>

  <div class="tabs">
    <button class="active" data-tab="edu">Education</button>
    <button data-tab="exp">Experience</button>
  </div>
  <div class="tab-content">
    <div id="edu" class="active">
      <ul>
        <li><strong>2025â€“2026:</strong> M.Sc. M2 Mechatronics, Machine Vision and Artificial Intelligence, Paris-Saclay University</li>
        <li><strong>2024â€“2025:</strong> M.Sc. M1 Electrical Engineering (Computer Vision Track), Paris-Saclay University</li>
        <li><strong>2019â€“2023:</strong> B.Sc. Mechatronics, VNU-HN (Valedictorian)</li>
      </ul>
    </div>
    <div id="exp">
      <ul>
        <li><strong>2022-2024:</strong> Teaching Assistant, Vietnam National University</li>
        <li><strong>2023-2025:</strong> Research Assistant, National Chung Cheng University</li>
        <li><strong>2025:</strong> Research Intern, Westlake University</li>
      </ul>
    </div>
  </div>
</section>

<!-- Research Interests - FIXED VERSION --> 
<section id="research">
  <h2>Research Interests</h2>
  <ul class="research-grid">
    <li class="card">
      <div class="icon-wrapper" data-icon="âš¡"></div>
      <div class="card-content">
        <h3>Efficient Deep Learning</h3>
        <p>Network pruning, quantization &amp; lightweight architectures</p>
      </div>
    </li>
    <li class="card">
      <div class="icon-wrapper" data-icon="ðŸŽ¯"></div>
      <div class="card-content">
        <h3>3D Reconstruction (NeRF)</h3>
        <p>Neural radiance fields &amp; novel-view synthesis</p>
      </div>
    </li>
    <li class="card">
      <div class="icon-wrapper" data-icon="ðŸŒŠ"></div>
      <div class="card-content">
        <h3>Diffusion Models</h3>
        <p>Generative modeling &amp; image synthesis</p>
      </div>
    </li>
    <li class="card">
      <div class="icon-wrapper" data-icon="ðŸ¥"></div>
      <div class="card-content">
        <h3>Medical Image Analysis</h3>
        <p>Segmentation, detection &amp; diagnostic AI</p>
      </div>
    </li>
  </ul>
</section>


<!-- Projects -->
  <section id="projects">
    <h2>Key Projects</h2>
    <div class="grid">
      <div class="project-card">
        <img src="https://images.unsplash.com/photo-1560493676-04071c5f467b?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1000&q=80" alt="Plant Disease Detection">
        <div class="project-card-content">
          <h3>Transformer-based Plant Disease Detection</h3>
          <p>Novel lightweight YOLO model with SCAT and Ghost convolution for real-time strawberry disease detection. Achieved mAP@0.5 of 80.3% with 8% improvement over baseline.</p>
          <p class="links">
            <a href="https://bom.so/VsURJZ">Paper</a>
            <a href="https://github.com/Tyler-Do">GitHub</a>
          </p>
        </div>
      </div>
      <div class="project-card">
        <img src="https://images.unsplash.com/photo-1473968512647-3e447244af8f?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1000&q=80" alt="UAV Detection">
        <div class="project-card-content">
          <h3>UAV-based Human Detection</h3>
          <p>Enhanced image processing algorithms for unmanned aerial vehicle operations. Built dataset with 6,600+ labeled bounding boxes across various environments.</p>
          <p class="links">
            <a href="https://doi.org/10.1109/ICSSE58758.2023.10227141">Paper</a>
            <a href="https://github.com/Tyler-Do">GitHub</a>
          </p>
        </div>
      </div>
      <div class="project-card">
        <img src="https://images.unsplash.com/photo-1559757148-5c350d0d3c56?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1000&q=80" alt="Medical AI">
        <div class="project-card-content">
          <h3>Minimally Invasive Surgical Tool Detection</h3>
          <p>Deep learning framework for real-time surgical tool detection using YOLOv8s. Achieved 98.6% mAP@0.5 on Surgical Tools and 95.7% on m2cai16-tool-locations dataset.</p>
          <p class="links">
            <a href="https://github.com/Tyler-Do">GitHub</a>
            <a href="https://colab.research.google.com/">Colab</a>
          </p>
        </div>
      </div>
      <div class="project-card">
        <img src="https://images.unsplash.com/photo-1565008447742-97f6f38c985c?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1000&q=80" alt="Conveyor Belt">
        <div class="project-card-content">
          <h3>AI-Based Product Classification</h3>
          <p>Developed AI-based sorting system using YOLOv5 on Raspberry Pi with infrared sensors. Achieved 90%+ accuracy in classifying plastic bottles and water containers.</p>
          <p class="links">
            <a href="https://github.com/Tyler-Do">GitHub</a>
            <a href="https://colab.research.google.com/">Demo</a>
          </p>
        </div>
      </div>
      <div class="project-card">
        <img src="https://images.unsplash.com/photo-1581094794329-c8112a89af12?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1000&q=80" alt="PPE Detection">
        <div class="project-card-content">
          <h3>Personal Protective Equipment Detection</h3>
          <p>Improved YOLOv5 for real construction site PPE detection with targeted augmentations and attention mechanisms. Achieved 95% mAP for on-site safety monitoring.</p>
          <p class="links">
            <a href="https://bom.so/BaVzd">Paper</a>
            <a href="https://github.com/Tyler-Do">GitHub</a>
          </p>
        </div>
      </div>
      <div class="project-card">
        <img src="https://images.unsplash.com/photo-1446776653964-20c1d3a81b06?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1000&q=80" alt="Airplane Detection">
        <div class="project-card-content">
          <h3>YOLO-Ghost Airplane Detection</h3>
          <p>Enhanced YOLO-Ghost with C2f and CIoU loss for improved airplane detection accuracy on satellite imagery. Optimized for lightweight deployment.</p>
          <p class="links">
            <a href="https://bom.so/6WxGSL">Paper</a>
            <a href="https://github.com/Tyler-Do">GitHub</a>
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Publications -->
  <section id="publications">
    <h2>Publications</h2>
    <div class="accordion">
  
      <div class="item">
        <button>2024: Do et al., "Towards Improving Precision and Complexity of Transformer-based Cost-sensitive Learning Models for Plant Disease Detection" â€“ Frontiers in Computer Science (Q1)</button>
        <div class="content">
          <p>First-author: proposed a cost-sensitive loss for transformer detectors in real-time plant disease detection.</p>
          <p>
            <a href="https://doi.org/10.3389/fcomp.2024.1480481">DOI</a> |
            <a href="https://www.frontiersin.org/articles/10.3389/fcomp.2024.1480481/full">Full Text</a>
          </p>
        </div>
      </div>
  
      <div class="item">
        <button>2024: Nguyen et al., "Towards Lightweight Model Using Non-local-based Graph Convolution Neural Network for SQL Injection Detection" â€“ Egyptian Informatics Journal (Q1)</button>
        <div class="content">
          <p>Developed a non-local GCN architecture for SQL-injection detection with high accuracy and low complexity.</p>
          <p>
            <a href="https://bom.so/RzxaAP">PDF</a>
          </p>
        </div>
      </div>
  
      <div class="item">
        <button>2024: Nguyen et al., "Lightweight Graph Convolutional Network Based On Multi-Head Residual Attention For Hand Point Classification" â€“ IEEE International Conference on Visual Communications and Image Processing</button>
        <div class="content">
          <p>Introduced a multi-head residual attention GCN to improve hand-point classification in visual communication tasks.</p>
          <p>
            <a href="https://bom.so/2Mnw1d">PDF</a>
          </p>
        </div>
      </div>
  
      <div class="item">
        <button>2024: Do et al., "You Only Look Once Based-C2fGhost Using Efficient CIoU Loss Function for Airplane Detection" â€“ 9th International Conference on Frontiers of Signal Processing, France</button>
        <div class="content">
          <p>Enhanced YOLO-Ghost with C2f and CIoU loss to boost airplane detection accuracy on satellite imagery.</p>
          <p>
            <a href="https://bom.so/6WxGSL">Proceedings</a>
          </p>
        </div>
      </div>
  
      <div class="item">
        <button>2024: Nguyen et al., "RHM: Novel Graph Convolution Based on Non-Local Network for SQL Injection Identification" â€“ ISIE 2024 (33rd International Symposium on Industrial Electronics)</button>
        <div class="content">
          <p>Proposed RHM, a non-local GCN variant, achieving state-of-the-art performance on SQL injection datasets.</p>
          <p>
            <a href="https://bom.so/m27fa">PDF</a>
          </p>
        </div>
      </div>
  
      <div class="item">
        <button>2024: Nguyen et al., "Plant Pathology Identification Using Local-Global Feature Level Based on Transformer" â€“ Indonesian Journal of Electrical Engineering and Computer Science (Q3)</button>
        <div class="content">
          <p>Applied transformer-based local-global feature fusion for plant pathology classification with high F1-score.</p>
          <p>
            <a href="https://bom.so/RDw2k">PDF</a>
          </p>
        </div>
      </div>
  
      <div class="item">
        <button>2024: Kim et al., "An Effective Approach Utilizing Deep Learning for Detecting Lychee at Different Development Stages" â€“ The Journal of Food Process Engineering (under review, Q2)</button>
        <div class="content">
          <p>Demonstrated a CNN-based detector for lychee ripeness stages, achieving 92% accuracy across varied lighting.</p>
          <p>
            <a href="https://bom.so/wZuey">PDF</a>
          </p>
        </div>
      </div>
  
      <div class="item">
        <button>2023: Do et al., "You Only Look Once Based on Yolo Backbones-Transformer in UAVs" â€“ International Conference on System Science and Engineering</button>
        <div class="content">
          <p>Integrated transformer modules into YOLO for robust UAV-based human detection in diverse environments.</p>
          <p>
            <a href="https://doi.org/10.1109/ICSSE58758.2023.10227141">DOI</a>
          </p>
        </div>
      </div>
  
      <div class="item">
        <button>2023: Do et al., "An Improved YOLOv5 for Personal Protective Equipment Detection in Real Construction Site" â€“ International Conference on Computing and Communication Technologies</button>
        <div class="content">
          <p>Enhanced YOLOv5 with targeted augmentations and attention, achieving 95% mAP for PPE detection on site.</p>
          <p>
            <a href="https://bom.so/BaVzd">PDF</a>
          </p>
        </div>
      </div>
  
    </div>
  </section>

  <!-- Challenge Myself Blog -->
  <section id="blog">
    <h2>ðŸ’¡ Challenge Myself</h2>
    <ul class="challenge-list">
      <li>
        <strong>Implement SIoU Loss in PyTorch</strong><br>
        <a href="https://github.com/yourrepo-siou">GitHub</a>
        <a href="https://colab.research.google.com/yourcolab-siou">Colab</a>
        <a href="https://youtu.be/yourvideo-siou">YouTube</a>
      </li>
      <li>
        <strong>NeRF from Scratch</strong><br>
        <a href="https://github.com/yourrepo-nerf">GitHub</a>
        <a href="https://colab.research.google.com/yourcolab-nerf">Colab</a>
        <a href="https://youtu.be/yourvideo-nerf">YouTube</a>
      </li>
    </ul>
  </section>

  <!-- Contact / Footer -->
  <footer id="contact">
    <p>Email: <a href="mailto:domanhtuan824@gmail.com">domanhtuan824@gmail.com</a></p>
    <p>
      <a href="https://scholar.google.com/citations?user=0AdKxPkAAAAJ&hl=en">Google Scholar</a> |
      <a href="https://github.com/Tyler-Do">GitHub</a> |
      <a href="https://www.linkedin.com/in/manhtuando1608/">LinkedIn</a>
    </p>
    <p>Â© 2025 Manh Tuan Do</p>
  </footer>

  <script>
    // Tabs logic
    document.querySelectorAll('.tabs button').forEach(btn=>{
      btn.addEventListener('click', ()=>{
        document.querySelectorAll('.tabs button').forEach(b=>b.classList.remove('active'));
        document.querySelectorAll('.tab-content > div').forEach(c=>c.classList.remove('active'));
        btn.classList.add('active');
        document.getElementById(btn.dataset.tab).classList.add('active');
      });
    });
    // Accordion logic
    document.querySelectorAll('.accordion .item button').forEach(b=>{
      b.addEventListener('click', ()=>{
        const item = b.parentElement;
        item.classList.toggle('open');
      });
    });
  </script>
</body>
</html>
